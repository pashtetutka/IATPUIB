# Анализ данных сетевого трафика с помощью Apache Arrow
pashtet.2003@yandex.ru

# Использование Apache Arrow для анализа сетевого трафика

## Цель работы

1.  Освоить применение технологии **Apache Arrow** для работы с большими
    данными.
2.  Научиться использовать **R** и библиотеку **Arrow** для обработки и
    анализа данных.
3.  Выполнить анализ метаданных сетевого трафика.
4.  Закрепить навыки работы с облачными технологиями, такими как Yandex
    Object Storage и RStudio Server.
5.  Изучить возможности оптимизации кода для работы с большими данными в
    формате `.parquet`.

------------------------------------------------------------------------

## Исходные данные

1.  Операционная система: Windows 10 или Ubuntu 20.04.
2.  Инструменты: **RStudio Desktop**, библиотека `arrow`, и облачная IDE
    RStudio Server.
3.  Данные: набор сетевого трафика в формате `.parquet` (пример:
    `traffic_data.parquet`).

------------------------------------------------------------------------

## Задание

С использованием языка R, библиотеки `arrow` и облачной IDE RStudio
Server выполнить следующие задачи:

1.  Обнаружить утечку данных.
2.  Выявить IP-адреса с ненормальной активностью в нерабочие часы.
3.  Найти хосты, использующие нестандартные порты для передачи данных.

------------------------------------------------------------------------

## Ход работы

### 1. Импорт данных

Загружаем необходимые библиотеки и данные в формате Parquet:

``` r
library(arrow)
```


    Присоединяю пакет: 'arrow'

    Следующий объект скрыт от 'package:utils':

        timestamp

``` r
library(tidyverse)
```

    ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ✔ purrr     1.0.2     

    ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ✖ lubridate::duration() masks arrow::duration()
    ✖ dplyr::filter()       masks stats::filter()
    ✖ dplyr::lag()          masks stats::lag()
    ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(lubridate)

# Загрузка данных
traffic_data <- read_parquet("tm_data.pqt", use_threads = FALSE)

# Просмотр структуры данных
print(glimpse(traffic_data))
```

    Rows: 105,747,730
    Columns: 5
    $ timestamp <dbl> 1.578326e+12, 1.578326e+12, 1.578326e+12, 1.578326e+12, 1.57…
    $ src       <chr> "13.43.52.51", "16.79.101.100", "18.43.118.103", "15.71.108.…
    $ dst       <chr> "18.70.112.62", "12.48.65.39", "14.51.30.86", "14.50.119.33"…
    $ port      <int> 40, 92, 27, 57, 115, 92, 65, 123, 79, 72, 123, 123, 22, 118,…
    $ bytes     <int> 57354, 11895, 898, 7496, 20979, 8620, 46033, 1500, 979, 1036…
    # A tibble: 105,747,730 × 5
           timestamp src           dst           port bytes
     *         <dbl> <chr>         <chr>        <int> <int>
     1 1578326400001 13.43.52.51   18.70.112.62    40 57354
     2 1578326400005 16.79.101.100 12.48.65.39     92 11895
     3 1578326400007 18.43.118.103 14.51.30.86     27   898
     4 1578326400011 15.71.108.118 14.50.119.33    57  7496
     5 1578326400012 14.33.30.103  15.24.31.23    115 20979
     6 1578326400012 18.121.115.31 13.56.39.74     92  8620
     7 1578326400014 16.108.75.29  14.34.34.69     65 46033
     8 1578326400018 12.46.104.126 16.25.76.33    123  1500
     9 1578326400021 12.43.98.93   18.85.31.68     79   979
    10 1578326400021 14.32.60.107  12.30.62.113    72  1036
    # ℹ 105,747,720 more rows

------------------------------------------------------------------------

### 2. Задание 1. Обнаружение утечки данных

Определяем IP-адрес хоста, пересылающего наибольшее количество данных на
внешние ресурсы, исключая локальные адреса:

``` r
outside_traffic <- traffic_data %>%
  filter(
    str_detect(src, "^12.|^13.|^14.") & !str_detect(dst, "^12.|^13.|^14.")
  ) %>%
  group_by(src) %>%
  summarise(total_bytes = sum(bytes), .groups = "drop") %>%
  arrange(desc(total_bytes)) %>%
  filter(total_bytes > 6e9)

print(outside_traffic)
```

    # A tibble: 1 × 2
      src          total_bytes
      <chr>              <dbl>
    1 13.37.84.125 10625497574

------------------------------------------------------------------------

### 3. Задание 2. Ненормальная активность в нерабочие часы

Определяем IP-адреса систем с повышенной активностью в ночное время
(00:00–06:00), исключая ранее найденного нарушителя:

``` r
# Добавляем колонку с временной меткой и часами
traffic_data <- traffic_data %>%
  mutate(
    timestamp = as_datetime(timestamp / 1000),
    hour = hour(timestamp)
  )

night_activity <- traffic_data %>%
  filter(
    hour >= 0 & hour < 6,
    str_detect(src, "^12.|^13.|^14.") & !str_detect(dst, "^12.|^13.|^14.")
  ) %>%
  group_by(src) %>%
  summarise(total_bytes = sum(bytes), .groups = "drop") %>%
  arrange(desc(total_bytes))

print(night_activity)
```

    # A tibble: 1,000 × 2
       src          total_bytes
       <chr>              <int>
     1 13.37.84.125   288775978
     2 13.48.72.30     48220925
     3 14.51.30.86     44969599
     4 12.59.25.34     43313693
     5 14.51.75.107    42125333
     6 12.56.32.111    41226588
     7 12.58.68.102    41107666
     8 12.37.36.110    40780505
     9 14.57.50.29     40310397
    10 13.39.46.94     40276716
    # ℹ 990 more rows

------------------------------------------------------------------------

### 4. Задание 3. Использование нестандартного порта для утечки данных

Выявляем IP-адреса, использующие нестандартные порты для передачи
данных:

``` r
# Анализ использования портов
port_analysis <- traffic_data %>%
  filter(
    str_detect(src, "^12.|^13.|^14.") & !str_detect(dst, "^12.|^13.|^14.")
  ) %>%
  group_by(port) %>%
  summarise(
    total_bytes = sum(bytes),
    avg_bytes = mean(bytes),
    max_bytes = max(bytes),
    .groups = "drop"
  ) %>%
  arrange(desc(total_bytes))

print(port_analysis)
```

    # A tibble: 52 × 4
        port total_bytes avg_bytes max_bytes
       <int>       <dbl>     <dbl>     <int>
     1    92 32323402755    35126.    182077
     2    44 32297756123    35116.    179574
     3    56 32283549010    35124.    183523
     4    81 32268932688    35128.    192430
     5    39 32252111240    35141.    198527
     6   102 32246493592    35090.    193588
     7    57 32239663018    35093.    180469
     8    52 32234557986    35087.    184543
     9    74 32233139772    35096.    189818
    10   118 32230876324    35085.    186905
    # ℹ 42 more rows

``` r
# Определение IP-адресов с подозрительным портом (например, порт 37)
suspicious_ips <- traffic_data %>%
  filter(port == 37) %>%
  group_by(src) %>%
  summarise(total_bytes = sum(bytes), .groups = "drop") %>%
  arrange(desc(total_bytes))

print(suspicious_ips)
```

    # A tibble: 5,996 × 2
       src          total_bytes
       <chr>              <int>
     1 12.59.25.34     94819664
     2 14.57.50.29     91064449
     3 12.56.32.111    90873413
     4 14.57.60.122    90592414
     5 13.39.46.94     90484512
     6 12.45.94.34     89026418
     7 14.57.70.39     88554119
     8 14.51.30.86     88364662
     9 12.54.40.45     88142981
    10 14.51.75.107    86904061
    # ℹ 5,986 more rows

------------------------------------------------------------------------

## Оценка результата

1.  Были успешно выполнены задачи по анализу сетевого трафика с
    использованием библиотеки `arrow`.
2.  Определены IP-адреса, связанные с утечкой данных, повышенной
    активностью в ночное время и использованием нестандартных портов.
3.  Оптимизированы методы работы с большими данными, такие как агрегация
    и фильтрация.

------------------------------------------------------------------------

## Вывод

Применение технологии **Apache Arrow** и языка R позволило эффективно
проанализировать большой набор данных сетевого трафика. Использование
формата Parquet совместно с библиотекой Arrow обеспечило высокую
производительность и удобство обработки данных. Выявленные IP-адреса
дают возможность более детально изучить потенциальные инциденты
безопасности.
